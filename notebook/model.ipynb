{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6aaa782f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4684a05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    new_df = pd.read_csv('../data/predictions.csv')\n",
    "    df2 = pd.read_csv('../data/relevance_data.csv')\n",
    "    return new_df, df2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1c7c57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_data(new_df, df2):\n",
    "    merged_df = pd.merge(new_df, df2, on='DocumentID')\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77f77066",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(merged_df):\n",
    "    # Filter by relevant regulation\n",
    "    filtered_df = merged_df[merged_df['ContainsRelevantRegulation'] == True]\n",
    "    \n",
    "    # Count DocumentIDs\n",
    "    DocumentID_count = filtered_df['DocumentID'].value_counts().reset_index()\n",
    "    DocumentID_count.columns = ['DocumentID', 'Count']\n",
    "    \n",
    "    # Count DocumentIDs in the entire dataset\n",
    "    tope_3 = merged_df['DocumentID'].value_counts().reset_index()\n",
    "    tope_3.columns = ['DocumentID', 'Count']\n",
    "    \n",
    "    # Merge counts and calculate percentage\n",
    "    merged_DocumentID = pd.merge(DocumentID_count, tope_3, on='DocumentID', suffixes=('_document_counts', '_tope3'))\n",
    "    merged_DocumentID['Percentage'] = (merged_DocumentID['Count_document_counts'] / merged_DocumentID['Count_tope3']) * 100\n",
    "    \n",
    "    # Assign points based on percentage\n",
    "    def assign_points(percentage):\n",
    "        if percentage < 33:\n",
    "            return 1\n",
    "        elif 33 <= percentage < 50:\n",
    "            return 2\n",
    "        elif 50 <= percentage < 75:\n",
    "            return 3\n",
    "        elif 75 <= percentage < 100:\n",
    "            return 4\n",
    "        elif percentage == 100:\n",
    "            return 5\n",
    "    \n",
    "    merged_DocumentID['Points'] = merged_DocumentID['Percentage'].apply(assign_points)\n",
    "    \n",
    "    # Merge points back to the main DataFrame\n",
    "    merged_df = merged_df.merge(merged_DocumentID[['DocumentID', 'Points']], on='DocumentID', how='left')\n",
    "    merged_df['Points'].fillna(0, inplace=True)\n",
    "    merged_df['Points'] = merged_df['Points'].astype(int)\n",
    "    \n",
    "    return merged_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "abfe4ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    if isinstance(text, str):\n",
    "        soup = BeautifulSoup(text, \"html.parser\")\n",
    "        cleaned_text = soup.get_text()\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        words = cleaned_text.split()\n",
    "        filtered_text = ' '.join([word for word in words if word.lower() not in stop_words])\n",
    "        filtered_text = re.sub(r'[^\\w\\s]', '', filtered_text)\n",
    "        return filtered_text\n",
    "    else:\n",
    "        return ''\n",
    "    \n",
    "def clean_data(merged_df):\n",
    "    merged_df['Cleaned_Content'] = merged_df['Content'].apply(clean_text)\n",
    "    merged_df['Cleaned_Title'] = merged_df['Title'].apply(clean_text)\n",
    "    return merged_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61b0406a",
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = [\n",
    "    'financial', 'information', 'bank', 'article', 'date', \n",
    "    'securities', 'republic', 'paragraph', 'credit', 'data', \n",
    "    'their', 'risk', 'section', 'services', 'legal', \n",
    "    'accordance', 'reporting', 'all', 'state', 'foreign', \n",
    "    'person', 'market', '$', 'following', 'payment', \n",
    "    'investment', 'business', 'form', 'within', 'kazakhstan', \n",
    "    'management', 'provided', 'act', 'amount', 'requirements', \n",
    "    'account', 'exchange', 'service', 'public', 'electronic', \n",
    "    'national', 'case', 'been', 'into', 'tax', 'regulation',\n",
    "    'Compliance', 'Capital', 'Equity', 'Debt', 'Liability', \n",
    "    'Contract', 'Regulation', 'Jurisdiction', 'Governance', \n",
    "    'Fraud', 'Penalty', 'Transaction', 'Asset', 'Treasury', \n",
    "    'Audit', 'Disclosure', 'Insolvency', 'Bankruptcy', \n",
    "    'Merger', 'Acquisition', 'Divestiture', 'Antitrust', \n",
    "    'Fiduciary', 'Interest', 'Dividend', 'Bond', 'Stock', \n",
    "    'Shareholder', 'Portfolio', 'Arbitration', 'Litigation', \n",
    "    'Reconciliation', 'Custodian', 'Brokerage', 'Underwriting', \n",
    "    'Hedge', 'Derivative', 'Swap', 'Option', 'Valuation', \n",
    "    'Prospectus', 'Collateral', 'Leverage', 'Liquidation', \n",
    "    'Monetary', 'Remittance', 'Escrow', 'Fiscal'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64003b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_keywords(content, keywords):\n",
    "    if isinstance(content, str):\n",
    "        content_lower = content.lower()\n",
    "        return sum(1 for keyword in keywords if keyword in content_lower)\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def add_keyword_features(merged_df):\n",
    "#     keywords = [/* List of keywords */]\n",
    "    keywords_lower = [keyword.lower() for keyword in keywords]\n",
    "    \n",
    "    merged_df['keyword_count'] = merged_df['Cleaned_Content'].apply(lambda x: count_keywords(x, keywords_lower))\n",
    "    merged_df['keywords_point'] = merged_df['keyword_count'] * 0.1\n",
    "    \n",
    "    merged_df['total_point'] = merged_df['Points'] + merged_df['keywords_point']\n",
    "    merged_df['new_DocumentID'] = merged_df['total_point'].apply(lambda x: 1 if x > 4 else 0)\n",
    "    merged_df['new_DocumentTypeId'] = merged_df['total_point'].apply(lambda x: 1 if x > 5 else 0)\n",
    "    merged_df['new_RegulatorId'] = merged_df['total_point'].apply(lambda x: 1 if x > 4 else 0)\n",
    "    merged_df['new_pdf'] = merged_df['IsPdf'].astype(int)\n",
    "    print(merged_df.sample(20))\n",
    "    return merged_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2f977b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(df):\n",
    "    # Convert boolean target to binary\n",
    "    df['ContainsRelevantRegulation'] = df['ContainsRelevantRegulation'].astype(int)\n",
    "    \n",
    "    # Text features\n",
    "    vectorizer = TfidfVectorizer(stop_words='english', max_features=10000)\n",
    "    X_text = vectorizer.fit_transform(df['Cleaned_Content'] + ' ' + df['Cleaned_Title'])\n",
    "    \n",
    "    # Combine text features with other features\n",
    "    X = pd.concat([pd.DataFrame(X_text.toarray()), df[['new_DocumentID', 'new_DocumentTypeId', 'new_RegulatorId', 'new_pdf']]], axis=1)\n",
    "    y = df['ContainsRelevantRegulation']\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Initialize and train the model\n",
    "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    os.makedirs('../models', exist_ok=True)\n",
    "    joblib.dump(model, '../models/regulation_predictor_model.pkl')\n",
    "\n",
    "    \n",
    "    \n",
    "    # Make predictions and evaluate\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6725c449",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clean_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-86bff26976ae>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmerged_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mrun_pipeline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-6-86bff26976ae>\u001b[0m in \u001b[0;36mrun_pipeline\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mmerged_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmerge_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mmerged_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeature_engineering\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmerged_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mmerged_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclean_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmerged_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mmerged_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madd_keyword_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmerged_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmerged_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'clean_data' is not defined"
     ]
    }
   ],
   "source": [
    "def run_pipeline():\n",
    "    new_df, df2 = load_data()\n",
    "    merged_df = merge_data(new_df, df2)\n",
    "    merged_df = feature_engineering(merged_df)\n",
    "    merged_df = clean_data(merged_df)\n",
    "    merged_df = add_keyword_features(merged_df)\n",
    "    model = train_model(merged_df)\n",
    "    \n",
    "run_pipeline()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeac5c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "tope = pd.read_csv(\"trt.csv\")\n",
    "tope = feature_engineering(tope)\n",
    "tope = clean_data(tope)\n",
    "tope = add_keyword_features(tope)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be090d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
